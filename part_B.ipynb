{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TECH 2 mandatory assignment - Part B\n",
    "\n",
    "Write your solution for Part B in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to import the data from the pure data file into lists. And also import the modules numpy, pandas and part_A(the file with the methods made using inbuilt and loops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142135623730951 1.4142135623730951 1.4142135623730951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aaykol001\\AppData\\Local\\Temp\\ipykernel_14484\\3586128562.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import part_A as pa\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_csv(\"data.csv\", header=None)\n",
    "\n",
    "lst100=df[0].dropna().tolist()\n",
    "lst1k=df[1].dropna().tolist()\n",
    "lst10k=df[2].dropna().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we look at loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.1 μs ± 8.45 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "312 μs ± 68.5 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "3.46 ms ± 683 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pa.std_loops(lst100)\n",
    "%timeit pa.std_loops(lst1k)\n",
    "%timeit pa.std_loops(lst10k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can look at builtin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.8 μs ± 450 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "221 μs ± 31.5 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "2.76 ms ± 565 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pa.std_builtin(lst100)\n",
    "%timeit pa.std_builtin(lst1k)\n",
    "%timeit pa.std_builtin(lst10k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The we can look at numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.7 μs ± 1.48 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "81.3 μs ± 19.2 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "691 μs ± 262 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.std(lst100)\n",
    "%timeit np.std(lst1k)\n",
    "%timeit np.std(lst10k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the timeits, it seems like numpy is the fastest, but not on the list which has a length of 100. Maybe because the base time needed for numpy to convert the list to an array is high enough on the first one to not justify any of the gains of its inherit ability to compute faster. Essentially, the fastest method for computing very long lists is numpy, however when looking at smaller lists, then using the builtin functions in Python may be better. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
